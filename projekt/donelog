This is the backlog of the TUwoC project. Items are prioritized by the product
owner and estimated by the team.

Pri  Estimation  Description
---------------------------Sprint10: 22. - 29. January -----------------------
001             Run the pipe
  16              Run with real world training set generated from the net

003             Cluster refinement
  03              Cluster titles
  08              keywords/tags

003             Cluster Refinement
  03              Cluster titles
  08              Cluster keywords/ tags (not checked out)

004             Documentation
  05              Quickstart on how to get pipeline running (add one Global-Driver)
  03              HowTo build for developers (not checked out)
  03              Mahout list presentation (not checked out)

005             UIMA quality optimization (06, not checked out)

006             Behemoth
  ??              HBase Layer
  ??              Feedback on analysis
---------------------------Sprint#9: 15. - 22. January -----------------------
001             Run the pipe
  16              Run with real world training set generated from the net
  12              Pipeline Tests
   1              Extract and store posting titles through Jericho
done except for pipeline running

002             Solr integration
  02              "Give me all other documents in the same cluster as this search result"
  03              "Search not only in documents but within cluster titles as well"
done

003             Cluster Refinement
  03              Cluster titles
  08              Cluster keywords/ tags (not checked out)
not done

004             Documentation
  05              Quickstart on how to get pipeline running (add one Global-Driver)
  03              HowTo build for developers (not checked out)
  03              Mahout list presentation (not checked out)
not done

005             UIMA quality optimization (06, not checked out)
not done

006             Behemoth
  ??              HBase Layer
  ??              Feedback on analysis
not done
---------------------------Sprint#8: 08. - 15. January -----------------------
001             Testing
  2.5             Uima Stop-word filter
  2.5             LingPipe Chunker
  6.5             Uima Mapper
  16              Feature pipeline
Done halfway - two more weeks estimated
  6.5             Support Felix
done
  ??              Mahout List Update
not done
  5               Boilerpipe
done half way - integration with jericho for title extraction missing.

(Total: 27)

---------------------------Sprint#7: 18. - 08. January -----------------------
001             Behemoth/Mahout
   03           Setup and run Behemoth
done
                Implement HBase layer
                Feed back current feature extraction annotators

002             Solr
   05           Simple WebUI (Velocity module, search box, 10 snippets, highlighting)
done
   02           Think of sensible pre-defined queries to demo the system
   05           Implement at least two such queries (implement as in integrate in UI)
not done
   05           Convert HBase to Solr generation to M/R job <- not checked out!
done

003             Tests
   08           Add tests to the implementation
not done
004             Processing Pipeline
   05           de-boilerplating (boilerpipe?)
done
005             Missing links (ordered by priority)
  05            Make heritrix less greedy
  02            Connect heritrix output and extraction input - evaluate how
  ??            Do the integration
done
  06.5          Feature extraction join - currently the pipe explodes w/ too much data
blocked by hadoop version
  02            Uima Pipe - normalising (remove special chars, lowercase)
done
  05            Uima Pipe - performance optimization
not done
end of checkout for this sprint

  05            Uima Pipe quality optimization
  03            Cluster title extraction
  08            Cluster keyword extraction/ tagging
  01            Store blog posting title in hbase as extracted by jericho
  ??            Training set generation
(Total: 27)

---------------------------Sprint#6: 11. - 18. Dezember ----------------------
001             Behemoth - not checked out
done

002             Get Pipeline integrated and running
    30
done

003             Solr loose ends
    02          create schema.xml
    01          setup solr
done

004             Tests - should be done during integration.
not done

005 08          Summary
not done (Total: 32)

---------------------------Sprint#5: 04. - 11. Dezember -----------------------
..........................Behemoth..........................
001		Behemoth
    05		work w/ community to include code
Not done.
002		Online algorithms
    00		decide and discuss
    08		Write summary
Not done.
003		kMeans
    02		post as title
Not done.
004		Feature vectors
    13		Random indexing
    02		Lingpipe
    08		Noun Group Chunker
Done.
005		Tests
    05		Increase coverage
Not done.
006		Integrate Solr
    08		XML configuration
    05		HBase content to xml
    03		HBase cluster assignments to xml
Done except for schema.xml
007	01	Maven Fix
Done.
008	02	Cleanser project fix
Done. (Total: 34)
---------------------------Sprint#4: 27. - 04. Dezember -----------------------
..........................k-Means...........................
001            kMeans
    Open       Chose arbitrary post as title.
    Open       Post Cluster Id assignment.
done except for title selection
.........................Online algorithm...................
002            Read up on Topic tracking
    08         Read papers + book and give an overview
done
........................Features and UIMA...................
003            Publish results reached so far
    05         Submit work done so far to mahout-user and get feedback
done
........................Solr................................
004            Solr indexing integration
               Typesystem
               Setup
               Document creation
               Cluster id assigment
               Mini gui
Not yet checked out.

.......................Testing..............................
005            Do insist on writing tests for everything.
    08         Deliver tests for currently stable components.
done for feature generation
.......................UIMA.................................
006            Add POS Tagging
    08         Add Tagger to Pipeline
    02         Read from HBase
    02         Write to HBase
done
---------------------------Sprint#3: 20. - 27. November -----------------------
...........................Crawler...........................
001		Crawl 10000 blogs
     03		Start crawl
     00		Start crawl once
     00		Know how recrawling is triggered
Done completly.
...........................UIMA...........................
002  		UIMA
      02	Stemming
      04	HBase Reader
      04	HBase Writer
      04	HTML Filter
      05	Pipeline
Done except for HBase integration.
...........................Features...........................
003		Feature Vectors
      08	Move to reading from HBase
Done completely.
...........................PManagement...........................
004		Mavenization
      03	Integrate with provided project stub and upload maven site
Done completely.
...........................Mahout...........................
005		kMeans
Not checked out
Done up to integration.
...........................Paper...........................
006		Algorithm
		Read up on online clustering algorithms
Done first round.
...........................Tests...........................
007		Provide Tests
      16	For all components available so far (target coverage: 80%)
Not done at all.
---------------------------Sprint#2: 13. - 20. November -----------------------
...........................UIMA...........................
001		UIMA for parsing
        	HBase Reader
      03	HTML Filter
      08	TLD Filter (done in Crawler)
      05	Setup pipeline
      02	HBase Writer
Not done at all (missing machine was one reason).

...........................Features...........................
002		Feature vector generation
      05	TFIDF Code as M/R job
Done, tests are still missing.

...........................Mahout...........................
003		Get kMeans up and running
      05	Start w/ example
      08	Cluster assigments
      03	Arbitrary doc as title
Done k-Means integration with feature generation. Rest not
checked out.

...........................Paper...........................
004		Decide on algorithm
      13	Discuss on list
      13	Design
Not checked out.

...........................Solr...........................
005		Solr integration
Not checked out.

---------------------------Sprint#1: 01. - 13. November -----------------------
...........................Crawler...........................
001 		Integrate Crawler and Hadoop
     13		Store documents in Hbase
     05		Retrieve docs from Hbase
     01		Retrieve blogs only
Done but still buggy.

...........................Mahout...........................
002		Integrate Mahout and HBase
     08		Gen vectors from docs to hdfs
     03		Use k-Means to cluster docs
     13		Use one post in cluster as title, cluster labels on docs
Started but not completed.

...........................Paper...........................
003		Kleinberg paper (including references)
     07		read and understand
     07		discuss internally
     21		discuss on mahout dev list
     13		start implementation
Done except for implementation.

...........................Lucene...........................
004		Clusters into lucene through fields
Not checked out.

---------------------------Sprint#0: 23. - 30. October ------------------------
...........................Open Source development.............................
001  02          Get acquainted with open source software development tools.
                 Goal: Everyone is able to checkout any Apache project, build
                 it from source, apply patches to it. Students are subscribed
                 to the mailinglists of those projects they are going to use
                 throughout the course. Students are able to generate patches
                 from code modifications, to be shown in documentation patches
                 that are submitted to your favourite project.
Done.

...........................Hadoop Setup........................................
003  02          Hadoop: Set up your first own cluster. Write a test job that
                 communicates with the database system to be used for document
                 storage after processing.
Done - except for document retrieval from database.

..........................Web Crawling........................................
005  02          Web Crawling: Set up a pipeline to crawl web pages that
                 stores the pages in a document database in HDFS.
Done - except for storage in HDFS.

..........................Solr setup..........................................
009  02          Setup a solr search server to index the annotated postings.
Done.
